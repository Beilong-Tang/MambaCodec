/DKUdata/tangbl/anaconda/envs/bltang/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.
  warnings.warn("torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.")
bypass_quantizer True
cuda:5
/DKUdata/tangbl/anaconda/envs/bltang/lib/python3.9/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
/DKUdata/tangbl/anaconda/envs/bltang/lib/python3.9/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
torch.Size([16, 1, 32000])
torch.Size([16, 1, 32000])
torch.Size([16, 1, 32000])
torch.Size([16, 1, 32000])
Traceback (most recent call last):
  File "/DKUdata/tangbl/MambaTransformer/train.py", line 68, in <module>
    main(args)
  File "/DKUdata/tangbl/MambaTransformer/train.py", line 53, in main
    trainer.train()
  File "/DKUdata/tangbl/MambaTransformer/trainer/mse_trainer.py", line 101, in train
    self._train(self.loss_fn, self.optim, self.tr_data, epoch)
  File "/DKUdata/tangbl/MambaTransformer/trainer/mse_trainer.py", line 48, in _train
    for batch, (mix_audio, clean_audio) in enumerate(tr_data):
  File "/DKUdata/tangbl/anaconda/envs/bltang/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/DKUdata/tangbl/anaconda/envs/bltang/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/DKUdata/tangbl/anaconda/envs/bltang/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/DKUdata/tangbl/anaconda/envs/bltang/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/DKUdata/tangbl/MambaTransformer/dataset/dataset.py", line 27, in __getitem__
    mix_audio,_ = torchaudio.load(self.mix[idx])
  File "/DKUdata/tangbl/anaconda/envs/bltang/lib/python3.9/site-packages/torchaudio/_backend/utils.py", line 205, in load
    return backend.load(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)
  File "/DKUdata/tangbl/anaconda/envs/bltang/lib/python3.9/site-packages/torchaudio/_backend/ffmpeg.py", line 297, in load
    return load_audio(uri, frame_offset, num_frames, normalize, channels_first, format)
  File "/DKUdata/tangbl/anaconda/envs/bltang/lib/python3.9/site-packages/torchaudio/_backend/ffmpeg.py", line 88, in load_audio
    s = torchaudio.io.StreamReader(src, format, None, buffer_size)
  File "/DKUdata/tangbl/anaconda/envs/bltang/lib/python3.9/site-packages/torio/io/_streaming_media_decoder.py", line 526, in __init__
    self._be = ffmpeg_ext.StreamingMediaDecoder(os.path.normpath(src), format, option)
KeyboardInterrupt
