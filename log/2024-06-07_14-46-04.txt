/DKUdata/tangbl/anaconda/envs/bltang/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.
  warnings.warn("torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.")
bypass_quantizer True
cuda:5
/DKUdata/tangbl/anaconda/envs/bltang/lib/python3.9/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
Traceback (most recent call last):
  File "/DKUdata/tangbl/MambaTransformer/train.py", line 71, in <module>
    main(args)
  File "/DKUdata/tangbl/MambaTransformer/train.py", line 46, in main
    trainer_class = get_class("trainer", f"{config['loss']}Trainer")
  File "/DKUdata/tangbl/MambaTransformer/utils.py", line 22, in get_class
    package = importlib.import_module(module_name)
UnboundLocalError: local variable 'module_name' referenced before assignment
